{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from time import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 3)\n",
    "input = Variable(torch.randn(128, 20))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "batch_size = 3\n",
    "hidden_size = 5\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 5]), torch.Size([3, 10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(batch_size, seq_len, hidden_size))\n",
    "labels = Variable(torch.ones(batch_size, seq_len).long())\n",
    "\n",
    "inputs.size(), labels.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class torch.nn.RNN(*args, **kwargs)\n",
    "\n",
    "### Parameters:\t\n",
    " - **input_size** – The number of expected features in the input x\n",
    " - **hidden_size** – The number of features in the hidden state h\n",
    " - **num_layers** – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    " - **nonlinearity** – The non-linearity to use. Can be either ‘tanh’ or ‘relu’. Default: ‘tanh’\n",
    " - **bias** – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    " - **batch_first** – If True, then the input and output tensors are provided as (batch, seq, feature)\n",
    " - **dropout** – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    " - **bidirectional** – If True, becomes a bidirectional RNN. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "h_n = Variable(torch.randn(1, batch_size, hidden_size))\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "opt = SGD(rnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.6322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.4481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.4049\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3851\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3535\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2.02\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(1000):\n",
    "    loss = 0\n",
    "    \n",
    "    out, last_h = rnn(inputs, h_n)\n",
    "    \n",
    "    # out: [batch_size, seq_len, hidden_size]\n",
    "    # lables: [batch_size, seq_len]\n",
    "    \n",
    "    for j in range(seq_len):\n",
    "        loss += loss_fn(out[:,j,:], labels[:,j])\n",
    "        \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(loss)\n",
    "\n",
    "print(f'{time() - start:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  0.1874 -0.7648 -0.0574  0.3063  0.3283 -0.8304  0.8753  0.7592  0.3851 -0.1417\n",
       "  0.5973 -0.0967  0.6885  0.0338  0.9345 -0.0655 -0.9436  0.8758 -0.9282 -0.4330\n",
       " [torch.FloatTensor of size 2x10], Variable containing:\n",
       "  0.7570 -0.3473  0.5445 -0.3237  0.9141 -0.4219  0.0067  0.4525  0.3122  0.2558\n",
       " -0.4528 -0.1836 -0.8534 -0.6030 -0.5890 -0.3248  0.0043 -0.8554  0.8664  0.4537\n",
       " [torch.FloatTensor of size 2x10]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNNCell(10, 10)\n",
    "_input = Variable(torch.randn(6, 2, 10))\n",
    "hx = Variable(torch.randn(2, 10))\n",
    "output = []\n",
    "for i in range(2):\n",
    "        hx = rnn(_input[i], hx)\n",
    "        output.append(hx)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnncell = nn.RNNCell(hidden_size, hidden_size)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "opt = SGD(rnncell.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  2.7433  0.0471  1.2622  0.2100 -0.3848\n",
      "  1.4554  0.3721 -2.4634  0.7018 -0.0480\n",
      "  2.2410 -0.9494 -1.4348 -0.0517  0.6590\n",
      " -0.5991 -0.7685 -1.3306 -2.2601  0.6363\n",
      " -0.1966  0.2830 -1.3152  1.4531 -2.1519\n",
      "  0.3345 -0.1216 -0.0286  0.2817  1.5224\n",
      " -0.6287  0.2152 -1.7900 -0.9344  0.0898\n",
      "  0.8218 -2.5248  1.0621  0.0030  0.4964\n",
      " -1.8711 -0.9957  1.3306  0.4637  0.2865\n",
      "  0.4904  0.8932 -1.2823 -1.1580  0.6046\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.1499  0.5721  0.7506 -0.3534  1.5718\n",
      "  1.3562  0.8376 -2.8787 -1.9997  0.7123\n",
      " -1.3980 -0.7345  0.1998  0.8465 -0.8675\n",
      " -0.1045 -0.5209  0.8285  0.4737 -1.2573\n",
      " -0.6930 -1.7201  0.1213  0.6195 -0.5531\n",
      " -0.1842  0.1953 -0.3475  0.0005 -0.3065\n",
      "  0.8331 -0.8477 -1.0281 -0.2570  0.8831\n",
      " -3.0522 -1.0129  0.3017 -0.8542  1.4732\n",
      " -1.3109  0.6289  0.6967 -1.3588 -1.0148\n",
      "  0.4323  0.4267  0.7468 -1.3492  0.9131\n",
      "\n",
      "(2 ,.,.) = \n",
      " -1.9109 -0.3432 -0.7599  1.5289  0.3528\n",
      " -0.3480 -0.2581  1.0816 -1.9361  0.1008\n",
      "  1.6056  0.1046 -0.1466  1.5988 -1.5952\n",
      "  1.4850 -0.2208  1.2335  0.8693  0.6063\n",
      "  1.6754  0.6101 -1.4118 -1.4533 -0.5400\n",
      "  1.1506  0.4433  1.5864  2.3083 -0.4665\n",
      "  0.3900  0.9155  1.0700  0.6789 -0.9406\n",
      "  1.5135 -0.4241 -1.4085 -1.3674  1.0792\n",
      " -0.9445  0.5626  0.2439 -0.5415 -0.3367\n",
      "  0.0790 -1.1743  0.7491 -0.5645  1.2742\n",
      "[torch.FloatTensor of size 3x10x5]\n",
      "\n",
      "Variable containing:\n",
      "    1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1\n",
      "[torch.LongTensor of size 3x10]\n",
      "\n",
      "Variable containing:\n",
      " 0.1540 -0.7405 -0.3795 -1.6395 -0.1284\n",
      " 0.0192 -0.7940  0.7273  0.0368 -0.8389\n",
      " 0.4807 -0.2226  0.2645 -0.5699  0.0543\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(batch_size,seq_len, hidden_size))\n",
    "labels = Variable(torch.ones(batch_size, seq_len).long())\n",
    "h = Variable(torch.randn(batch_size,hidden_size))\n",
    "print(inputs)\n",
    "print(labels)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.3372\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3366\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3361\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3357\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3352\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3349\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3342\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3339\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.3337\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1.77\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "output = []\n",
    "for i in range(1000):\n",
    "    loss = 0\n",
    "    \n",
    "    h_next = Variable(h.data.new(batch_size,hidden_size))\n",
    "\n",
    "    for j in range(seq_len):\n",
    "        h_next = rnncell(inputs[:,j,:], h_next)\n",
    "        loss += loss_fn(h_next, labels[:, j])\n",
    "        output.append(h_next)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(loss)\n",
    "\n",
    "print(f'{time() - start:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
