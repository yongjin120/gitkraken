{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hannanum Class\n",
    "    class konlpy.tag._hannanum.Hannanum(jvmpath=None)\n",
    "\n",
    "### Hannanum is a morphological analyzer and POS tagger\n",
    "\n",
    "- analyze(phrase)<br/>\n",
    "   Phrase analyzer.<br/>\n",
    "  This analyzer returns various morphological candidates for each token. It consists of two parts: 1) Dictionary search (chart), 2) Unclassified term segmentation.\n",
    "\n",
    "- morphs(phrase)<br/>\n",
    "  Parse phrase to morphemes.\n",
    "\n",
    "- nouns(phrase)<br/>\n",
    "  Noun extractor.\n",
    "\n",
    "- pos(phrase, ntags=9, flatten=True)<br/>\n",
    "  POS tagger.\n",
    "\n",
    "- This tagger is HMM based, and calculates the probability of tags.<br/>\n",
    "\n",
    ">매개 변수:\t<br/>\n",
    " - ntags – The number of tags. It can be either 9 or 22.<br/>\n",
    " - flatten – If False, preserves eojeols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[('롯데마트', 'ncn'), ('의', 'jcm')], [('롯데마트의', 'ncn')], [('롯데마트', 'nqq'), ('의', 'jcm')], [('롯데마트의', 'nqq')]], [[('흑마늘', 'ncn')], [('흑마늘', 'nqq')]], [[('양념', 'ncn')]], [[('치킨', 'ncn'), ('이', 'jcc')], [('치킨', 'ncn'), ('이', 'jcs')], [('치킨', 'ncn'), ('이', 'ncn')]], [[('논란', 'ncpa'), ('이', 'jcc')], [('논란', 'ncpa'), ('이', 'jcs')], [('논란', 'ncpa'), ('이', 'ncn')]], [[('되', 'nbu'), ('고', 'jcj')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecc')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecs')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecx')], [('되', 'paa'), ('고', 'ecc')], [('되', 'paa'), ('고', 'ecs')], [('되', 'paa'), ('고', 'ecx')], [('되', 'pvg'), ('고', 'ecc')], [('되', 'pvg'), ('고', 'ecs')], [('되', 'pvg'), ('고', 'ecx')], [('되', 'px'), ('고', 'ecc')], [('되', 'px'), ('고', 'ecs')], [('되', 'px'), ('고', 'ecx')]], [[('있', 'paa'), ('다', 'ef')], [('있', 'px'), ('다', 'ef')]], [[('.', 'sf')], [('.', 'sy')]]]\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.analyze(u'롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['롯데마트', '의', '흑마늘', '양념', '치킨', '이', '논란', '이', '되', '고', '있', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.morphs(u'롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['다람쥐', '쳇바퀴', '타고파']\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.nouns(u'다람쥐 헌 쳇바퀴에 타고파'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('웃', 'P'), ('으면', 'E'), ('더', 'M'), ('행복', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S')]\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.pos(u'웃으면 더 행복합니다!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kkma Class\n",
    "     class konlpy.tag._kkma.Kkma(jvmpath=None)\n",
    "### Kkma is a morphological analyzer and natural language processing system\n",
    "\n",
    "- morphs(phrase)<br/>\n",
    "  Parse phrase to morphemes.\n",
    "\n",
    "- nouns(phrase)<br/>\n",
    "  Noun extractor.<br/>\n",
    "  pos(phrase, flatten=True)<br/>\n",
    "  POS tagger.<br/>\n",
    "  \n",
    "  매개 변수:\tflatten – If False, preserves eojeols.\n",
    "\n",
    "- sentences(phrase)<br/>\n",
    "  Sentence detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공부', '를', '하', '면', '하', 'ㄹ수록', '모르', '는', '것', '이', '많', '다는', '것', '을', '알', '게', '되', 'ㅂ니다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(kkma.morphs(u'공부를 하면할수록 모르는게 많다는 것을 알게 됩니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['대학', '통계학', '이산', '이산수학', '수학', '등']\n"
     ]
    }
   ],
   "source": [
    "print(kkma.nouns(u'대학에서 DB, 통계학, 이산수학 등을 배웠지만...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('다', 'MAG'), ('까먹', 'VV'), ('어', 'ECD'), ('버리', 'VXV'), ('었', 'EPT'), ('네요', 'EFN'), ('?', 'SF'), ('ㅋㅋ', 'EMO')]\n"
     ]
    }
   ],
   "source": [
    "print(kkma.pos(u'다 까먹어버렸네요?ㅋㅋ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그래도 계속 공부합니다.', '재밌으니까!']\n"
     ]
    }
   ],
   "source": [
    "print(kkma.sentences(u'그래도 계속 공부합니다. 재밌으니까!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Komoran Class\n",
    "    class konlpy.tag._komoran.Komoran(jvmpath=None, dicpath=None)\n",
    "    \n",
    "### KOMORAN is a relatively new open source Korean morphological analyzer     \n",
    "\n",
    "- morphs(phrase)<br/>\n",
    "  Parse phrase to morphemes.\n",
    "\n",
    "- nouns(phrase)<br/>\n",
    "  Noun extractor.\n",
    "\n",
    "- pos(phrase, flatten=True)<br/>\n",
    "  POS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우왕', '코', '모란', '도', '오픈소스', '가', '되', '었', '어요']\n"
     ]
    }
   ],
   "source": [
    "print(komoran.morphs(u'우왕 코모란도 오픈소스가 되었어요'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오픈소스', '관심', '개발자']\n"
     ]
    }
   ],
   "source": [
    "print(komoran.nouns(u'오픈소스에 관심 많은 멋진 개발자님들!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('원칙', 'NNG'), ('이나', 'JC'), ('기체', 'NNG'), ('설계', 'NNG'), ('와', 'JC'), ('엔진', 'NNG'), ('·', 'SP'), ('레이더', 'NNG'), ('·', 'SP'), ('항법', 'NNP'), ('장비', 'NNG'), ('등', 'NNB')]\n"
     ]
    }
   ],
   "source": [
    "print(komoran.pos(u'원칙이나 기체 설계와 엔진·레이더·항법장비 등'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Class\n",
    "    class konlpy.tag._twitter.Twitter(jvmpath=None)\n",
    "### Twitter Korean Text is an open source Korean tokenizer written in Scala\n",
    "\n",
    "- morphs(phrase)<br/>\n",
    "Parse phrase to morphemes.\n",
    "\n",
    "- nouns(phrase)<br/>\n",
    "Noun extractor.\n",
    "\n",
    "- phrases(phrase)<br/>\n",
    "Phrase extractor.\n",
    "\n",
    "- pos(phrase, norm=False, stem=False)<br/>\n",
    "POS tagger. In contrast to other classes in this subpackage, this POS tagger doesn’t have a flatten option, but has norm and stem options. Check the parameter list below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.morphs(u'단독입찰보다 복수입찰의 경우'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['유일하', '항공기', '체계', '종합', '개발', '경험']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['분석', '분석과 신뢰감', '신뢰감', '분석과 신뢰감 있는 진행', '신뢰감 있는 진행', '진행', '신뢰']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.phrases(u'날카로운 분석과 신뢰감 있는 진행으로'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter.pos(u'이것도 되나욬ㅋㅋ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되', 'Verb'), ('나요', 'Eomi'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter.pos(u'이것도 되나욬ㅋㅋ', norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
