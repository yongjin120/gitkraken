{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from konlpy.tag import Kkma\n",
    "tagger= Kkma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNNCell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h′=tanh(wih∗x+bih+whh∗h+bhh)$$\n",
    "class torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7 # input dimension (word embedding) D\n",
    "hidden_size = 30 # hidden dimension H\n",
    "batch_size = 3\n",
    "length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnncell = nn.RNNCell(input_size=input_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               bias=True, \n",
    "                               nonlinearity='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNCell(7, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnncell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(length, batch_size, input_size)) # T, B, D    (embedding matrix에서 인덱싱한 워드 벡터)\n",
    "hidden = Variable(torch.zeros(batch_size, hidden_size)) # first hidden state\n",
    "output = []\n",
    "for i in range(length):\n",
    "    hidden = rnncell(input[i], hidden)\n",
    "    output.append(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size() # Batch size, Hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1387, -0.1960, -0.1948, -0.4071, -0.0709, -0.1428,  0.0559,\n",
       "          -0.0700, -0.0183,  0.1165, -0.5116,  0.0152, -0.3726,  0.1087,\n",
       "          -0.1083, -0.0054,  0.2544,  0.2849, -0.2834, -0.0698,  0.2597,\n",
       "          -0.0167, -0.4322,  0.0872,  0.0709,  0.4363,  0.5371,  0.3305,\n",
       "          -0.3622, -0.0763],\n",
       "         [ 0.2018,  0.0750,  0.0865,  0.2297,  0.1160, -0.2435,  0.3663,\n",
       "          -0.2089, -0.2707,  0.0472,  0.1430,  0.3238, -0.2474, -0.0757,\n",
       "           0.4768,  0.0509, -0.0355,  0.0320,  0.1231, -0.2651, -0.0207,\n",
       "          -0.0577, -0.2245, -0.2263,  0.0323,  0.5218,  0.1249,  0.2893,\n",
       "          -0.1953, -0.1859],\n",
       "         [-0.1803, -0.1973, -0.0838, -0.0376, -0.1198, -0.2727, -0.0943,\n",
       "          -0.4005,  0.0620, -0.3936, -0.1270,  0.5793, -0.3176, -0.5552,\n",
       "           0.3895, -0.3903, -0.0843,  0.0834,  0.0636, -0.3057,  0.1149,\n",
       "          -0.1081, -0.3499, -0.4602,  0.3169,  0.3554,  0.1644,  0.2450,\n",
       "          -0.0294, -0.3000]]),\n",
       " tensor([[-0.2224, -0.0178, -0.3118, -0.2661, -0.1551,  0.0517,  0.0638,\n",
       "          -0.0137,  0.3611,  0.2723, -0.5039,  0.1995, -0.5034,  0.2542,\n",
       "          -0.1424, -0.1328,  0.5533,  0.1930, -0.5332, -0.4112, -0.2466,\n",
       "          -0.4168, -0.3350, -0.0791, -0.0286,  0.3841,  0.4386,  0.0136,\n",
       "          -0.3381, -0.1225],\n",
       "         [ 0.0656,  0.2675, -0.4692,  0.5253, -0.2065,  0.2303,  0.0012,\n",
       "           0.1850, -0.4345, -0.0001,  0.2954,  0.1186,  0.2036,  0.3463,\n",
       "           0.4744, -0.1389,  0.4662,  0.1625, -0.4973,  0.0874, -0.3895,\n",
       "          -0.6550, -0.1354,  0.0301, -0.4256,  0.2042,  0.5510,  0.2657,\n",
       "          -0.5176, -0.6854],\n",
       "         [ 0.2257,  0.3857, -0.4817,  0.0010, -0.0250,  0.2131,  0.2001,\n",
       "           0.2781,  0.2556,  0.1383, -0.4515,  0.1572, -0.1966,  0.3256,\n",
       "           0.2362,  0.2008,  0.2937,  0.2456, -0.4838, -0.3230, -0.3831,\n",
       "          -0.5323, -0.1891,  0.0021, -0.3134,  0.3022,  0.4625,  0.3353,\n",
       "          -0.5102, -0.2195]]),\n",
       " tensor([[-0.0295,  0.1134,  0.1664, -0.1333, -0.0004,  0.4440,  0.1743,\n",
       "           0.0842,  0.4270,  0.2245, -0.0610,  0.1661,  0.0283,  0.6009,\n",
       "           0.0581, -0.1984,  0.4378, -0.2238, -0.3765, -0.0756, -0.5094,\n",
       "          -0.0022, -0.1833,  0.5376, -0.2364,  0.1210,  0.5144,  0.0522,\n",
       "          -0.3848, -0.2736],\n",
       "         [-0.2051, -0.5549, -0.0449,  0.8710, -0.1350, -0.6284,  0.2418,\n",
       "          -0.2977,  0.1434,  0.3306,  0.6460, -0.2859, -0.4063, -0.2062,\n",
       "           0.3106, -0.3958,  0.6348,  0.1763, -0.0418,  0.2223, -0.0448,\n",
       "          -0.3899, -0.3235,  0.3339,  0.3983, -0.2186, -0.1850,  0.0029,\n",
       "          -0.0350, -0.0087],\n",
       "         [-0.2279, -0.3697,  0.1647,  0.7095, -0.2069, -0.2623,  0.1853,\n",
       "          -0.2464,  0.1356, -0.0399,  0.4573,  0.2431, -0.0923, -0.0172,\n",
       "           0.3735, -0.5510,  0.4580,  0.1765, -0.4479, -0.0875, -0.3951,\n",
       "          -0.0508, -0.1352, -0.0129,  0.1080,  0.0087,  0.3485,  0.2853,\n",
       "          -0.1552, -0.2835]]),\n",
       " tensor([[-0.1544, -0.0002, -0.5341, -0.1310, -0.2895, -0.0211, -0.4440,\n",
       "          -0.2680, -0.1328, -0.1582, -0.1103,  0.3083, -0.0241, -0.2989,\n",
       "           0.2215, -0.2654,  0.4986,  0.1562, -0.4174,  0.0201, -0.2073,\n",
       "          -0.3036, -0.4584, -0.0807,  0.1566,  0.0815,  0.6907, -0.0504,\n",
       "          -0.3968, -0.4303],\n",
       "         [-0.0566,  0.2825,  0.4741, -0.0623,  0.4994, -0.0730,  0.8063,\n",
       "           0.0867, -0.1264,  0.3544, -0.1291,  0.1984, -0.4432,  0.3552,\n",
       "           0.3565, -0.3634, -0.2408,  0.0019,  0.2857, -0.2437,  0.6620,\n",
       "           0.2651, -0.1054,  0.1236,  0.1047,  0.6099, -0.2566,  0.4536,\n",
       "          -0.0236,  0.0662],\n",
       "         [-0.1004,  0.0539,  0.5222, -0.5504,  0.2911, -0.0764,  0.3160,\n",
       "          -0.1558,  0.1250, -0.3236, -0.0750,  0.2808, -0.1256,  0.1117,\n",
       "           0.1594, -0.5224, -0.3581, -0.2524,  0.4018,  0.2588,  0.6801,\n",
       "           0.4313, -0.1990,  0.5757,  0.4842,  0.0487,  0.2045,  0.3784,\n",
       "          -0.0874, -0.2563]]),\n",
       " tensor([[-0.1154,  0.1061, -0.4828, -0.2446, -0.2614, -0.0236, -0.5449,\n",
       "          -0.0881,  0.1617, -0.4595, -0.2405,  0.3606, -0.1330, -0.4346,\n",
       "           0.5410, -0.2312, -0.0568,  0.1849, -0.3693, -0.1656, -0.0443,\n",
       "          -0.4568, -0.5079, -0.2290,  0.1248,  0.3895,  0.4926,  0.4126,\n",
       "          -0.1843, -0.5220],\n",
       "         [-0.4395, -0.3856,  0.2565, -0.0656, -0.1446, -0.1082,  0.2406,\n",
       "          -0.3741,  0.0908, -0.2406,  0.0029,  0.6162, -0.3910, -0.1159,\n",
       "          -0.0392, -0.6984,  0.2599, -0.0478, -0.0217, -0.0755,  0.1232,\n",
       "          -0.1111, -0.0901, -0.1020,  0.3610,  0.1660,  0.0883,  0.1020,\n",
       "          -0.1636, -0.3279],\n",
       "         [-0.1682, -0.0197,  0.2353, -0.3299, -0.0116, -0.0269,  0.1081,\n",
       "          -0.2263, -0.1507, -0.2004, -0.1333, -0.1258, -0.0165,  0.2757,\n",
       "          -0.3205, -0.2210,  0.0276, -0.2818, -0.2736,  0.3576,  0.2378,\n",
       "           0.0632, -0.1585,  0.4654,  0.2852,  0.0792,  0.4758, -0.0515,\n",
       "          -0.6151, -0.4777]]),\n",
       " tensor([[-0.2883, -0.5113,  0.5696,  0.5913, -0.2005, -0.4016,  0.2487,\n",
       "          -0.5564,  0.6247, -0.2483,  0.3952,  0.0136, -0.3230, -0.4070,\n",
       "           0.1159, -0.5771,  0.0417, -0.3247, -0.0433,  0.2128, -0.0937,\n",
       "           0.0451, -0.2178,  0.3850,  0.6492, -0.3568, -0.2789,  0.1870,\n",
       "          -0.0687, -0.1638],\n",
       "         [ 0.2018,  0.0544, -0.3448,  0.2954,  0.1103, -0.2352,  0.2569,\n",
       "          -0.1558,  0.3551,  0.3100, -0.0056, -0.2295, -0.4128,  0.2092,\n",
       "           0.0604, -0.0364,  0.5803, -0.0801, -0.2238,  0.0463, -0.2264,\n",
       "          -0.4863, -0.2245,  0.3896,  0.1147, -0.0189, -0.0515, -0.3904,\n",
       "          -0.4968,  0.0677],\n",
       "         [-0.2460,  0.2211,  0.2106,  0.0997,  0.0713,  0.1014,  0.1401,\n",
       "          -0.2772,  0.2885, -0.1959,  0.0498,  0.5580,  0.0512,  0.1254,\n",
       "           0.0741, -0.3097, -0.0225, -0.4864,  0.2388, -0.2684, -0.1821,\n",
       "          -0.1160, -0.2279,  0.0369,  0.2025,  0.0831,  0.1905, -0.2234,\n",
       "          -0.1870, -0.4769]]),\n",
       " tensor([[-0.2699,  0.0002,  0.6116, -0.4911,  0.2486, -0.3498,  0.3065,\n",
       "          -0.5706, -0.0210, -0.6173, -0.1374,  0.4506, -0.0648, -0.3480,\n",
       "           0.1071, -0.7731, -0.6429, -0.3609,  0.3434,  0.3193,  0.8293,\n",
       "           0.5289, -0.1975,  0.1926,  0.7663,  0.1157, -0.0718,  0.3825,\n",
       "          -0.2053, -0.3212],\n",
       "         [-0.0113, -0.0146,  0.0823,  0.7614, -0.2070,  0.1376,  0.1434,\n",
       "          -0.5212, -0.1001, -0.1220,  0.6504,  0.2011, -0.1835, -0.2272,\n",
       "           0.5373, -0.4029,  0.4147, -0.3544, -0.0232,  0.0594, -0.3095,\n",
       "          -0.4284, -0.2688,  0.2664,  0.1690, -0.0572, -0.0465, -0.5428,\n",
       "          -0.0891, -0.3817],\n",
       "         [ 0.0744,  0.0852,  0.5182,  0.8436,  0.1609, -0.2351,  0.6732,\n",
       "          -0.1008,  0.0948, -0.1307,  0.5625,  0.2856,  0.3606,  0.0643,\n",
       "           0.5106, -0.5463, -0.0885, -0.3063, -0.0645,  0.0947, -0.5206,\n",
       "           0.1355,  0.1038, -0.0711, -0.0120, -0.1469, -0.1805,  0.2839,\n",
       "          -0.2094, -0.3549]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN\n",
    "\n",
    "## class torch.nn.RNN(*args, **kwargs)\n",
    "### Parameters:\t\n",
    " - **input_size** – The number of expected features in the input x\n",
    " - **hidden_size** – The number of features in the hidden state h\n",
    " - **num_layers** – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    " - **nonlinearity** – The non-linearity to use. Can be either ‘tanh’ or ‘relu’. Default: ‘tanh’\n",
    " - **bias** – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    " - **batch_first** – If True, then the input and output tensors are provided as (batch, seq, feature)\n",
    " - **dropout** – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    " - **bidirectional** – If True, becomes a bidirectional RNN. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7\n",
    "hidden_size = 30\n",
    "batch_size = 16\n",
    "length = 4\n",
    "output_size = 7\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True) \n",
    "#,num_layers=1,bias=True,nonlinearity='tanh', batch_first=True, dropout=0, bidirectional=False)\n",
    "\n",
    "# (num_layers * num_directions, batch, hidden_size)\n",
    "input = Variable(torch.randn(batch_size, length,input_size)) # B,T,D  <= batch_first\n",
    "hidden = Variable(torch.zeros(1, batch_size, hidden_size)) # 1,B,H    (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "output, hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 30])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size() # B,T,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size() # 1,B,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(hidden_size,output_size)\n",
    "output = F.softmax(linear(output),1)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bidirectional RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size, hidden_size,num_layers=1,bias=True,nonlinearity='tanh', batch_first=True, dropout=0, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(batch_size,length,input_size)) # B,T,D\n",
    "hidden = Variable(torch.zeros(2,batch_size,hidden_size)) # 2,B,H    (num_layers * num_directions, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(input,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 60])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size() # concat of forward,backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size() # forward, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-layer RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 30\n",
    "batch_size = 3\n",
    "length = 4\n",
    "output_size = 5\n",
    "rnn = nn.RNN(input_size, \n",
    "             hidden_size, \n",
    "             num_layers=3,\n",
    "             bias=True, \n",
    "             nonlinearity='tanh', \n",
    "             batch_first=True, \n",
    "             dropout=0, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(batch_size,length,input_size)) # B,T,D\n",
    "hidden = Variable(torch.zeros(3*2,batch_size,hidden_size)) # 6,B,H    (num_layers * num_directions, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(input,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 60])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 30])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size() # (forward, backward)*num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(input_size,hidden_size,batch_first=True) #,num_layers=1,bias=True,batch_first=True,bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(batch_size,length,input_size)) # B,T,D\n",
    "hidden = Variable(torch.zeros(1,batch_size,hidden_size)) # 2,B,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(input,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 30])\n",
      "torch.Size([1, 3, 30])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(hidden.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LSTM\n",
    "<br/>\n",
    "\n",
    "Parameters:\t<br/>\n",
    "- input_size – The number of expected features in the input x<br/>\n",
    "- hidden_size – The number of features in the hidden state h<br/>\n",
    "- num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1<br/>\n",
    "- bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True<br/>\n",
    "- batch_first – If True, then the input and output tensors are provided as (batch, seq, feature)<br/>\n",
    "- dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0<br/>\n",
    "- bidirectional – If True, becomes a bidirectional LSTM. Default: False<br/>\n",
    "\n",
    ">Inputs: input, (h_0, c_0)<br/>\n",
    " - input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See torch.nn.utils.rnn.pack_padded_sequence() or torch.nn.utils.rnn.pack_sequence() for details.\n",
    " - h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch.\n",
    " - c_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    " - If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
    "\n",
    "> Outputs: output, (h_n, c_n)<br/>\n",
    " - output of shape (seq_len, batch, hidden_size * num_directions): tensor containing the output features (h_t) from the last layer of the LSTM, for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the input, the output will also be a packed sequence.\n",
    " - h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len\n",
    " - c_n (num_layers * num_directions, batch, hidden_size): tensor containing the cell state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = Variable(torch.randn(5, 3, 10))\n",
    "h0 = Variable(torch.randn(2, 3, 20))\n",
    "c0 = Variable(torch.randn(2, 3, 20))\n",
    "output, hn = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 30\n",
    "output_size = 10\n",
    "batch_size = 3\n",
    "length = 4\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size,\n",
    "              hidden_size,\n",
    "              num_layers=num_layers,\n",
    "              bias=True,\n",
    "              batch_first=True,\n",
    "              bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(batch_size,length,input_size)) # B,T,D\n",
    "hidden = Variable(torch.zeros(num_layers*2,batch_size,hidden_size)) # (num_layers * num_directions, batch, hidden_size)\n",
    "cell = Variable(torch.zeros(num_layers*2,batch_size,hidden_size)) # (num_layers * num_directions, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden,cell) = rnn(input,(hidden,cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 10])\n",
      "torch.Size([3, 4, 60])\n",
      "torch.Size([6, 3, 30])\n",
      "torch.Size([6, 3, 30])\n"
     ]
    }
   ],
   "source": [
    "print(input.size())\n",
    "print(output.size())\n",
    "print(hidden.size())\n",
    "print(cell.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(hidden_size*2, output_size)\n",
    "output = F.softmax(linear(output),1)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 각 timestep마다 그 다음에 올 단어를 예측하는 Language model을 만드시오 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음 Corpus(sentences)를 tokenized하고 Vocab을 만드시오\n",
    "* Embedding matrix(vector size는 10)\n",
    "* hidden state의 size가 20인 Bidirectional GRU(num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "tagger = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\"나는 오늘 삼계탕을 먹었다\",\"그런데도 배가 아직 고프다\",\"이제 영화보러 가야겠다 요즘 뭐가 재밌지\",\"날씨가 진짜 좋다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tagger.morphs(s) for s in sentences]\n",
    "vocab = list((set([token for tokens in tokenized for token in tokens])))\n",
    "word2index = {v:i for i,v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(word2index)\n",
    "D = 10\n",
    "H = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self,V,D,H):\n",
    "        super(LM,self).__init__()\n",
    "        self.hidden_size = H\n",
    "        \n",
    "        self.embed = nn.Embedding(V,D) # VxD\n",
    "        self.gru = nn.GRU(D,H,1,batch_first=True,bidirectional=True)\n",
    "        self.linear = nn.Linear(H*2,V)\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = Variable(torch.zeros(2,batch_size,self.hidden_size))\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs : B,T # LongTensor\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs) # B,T,D\n",
    "        hidden = self.init_hidden(inputs.size(0)) # 2,B,H\n",
    "        output, hidden = self.gru(embed,hidden)\n",
    "        # output : B,T,2H\n",
    "        # hidden : 2,B,H\n",
    "        \n",
    "        output = self.linear(output) # B,T,V\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(len(word2index),10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LM(\n",
       "  (embed): Embedding(29, 10)\n",
       "  (gru): GRU(10, 20, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=40, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Standard form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,embed_size,hidden_size,output_size,num_layers=1,bidirec=False):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirec:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "            \n",
    "        self.embed = nn.Embedding(input_size,embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,num_layers,batch_first=True,bidirectional=bidirec)\n",
    "        self.linear = nn.Linear(hidden_size*self.num_directions,output_size)\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        hidden = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        cell = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        return hidden, cell\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs : B,T\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs) # word vector indexing\n",
    "        hidden, cell = self.init_hidden(inputs.size(0)) # initial hidden,cell\n",
    "        \n",
    "        output, (hidden,cell) = self.lstm(embed,(hidden,cell))\n",
    "        \n",
    "        # Many-to-Many\n",
    "        output = self.linear(output) # B,T,H -> B,T,V\n",
    "        \n",
    "        # Many-to-One\n",
    "        #hidden = hidden[-self.num_directions:] # (num_directions,B,H)\n",
    "        #hidden = torch.cat([h for h in hidden],1)\n",
    "        #output = self.linear(hidden) # last hidden\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB=1000 # input_size\n",
    "EMBED = 50 # embedding_size\n",
    "HIDDEN = 100 # hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(VOCAB,EMBED,HIDDEN,VOCAB,bidirec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = Variable(torch.randperm(32*10)).view(32,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  20,  180,  179,  244,   29,  252,   42,  215,   59,  133],\n",
       "        [  85,  115,    0,   57,  271,  114,  318,    3,   56,  232],\n",
       "        [  11,   25,  309,   77,  146,  248,  296,  316,  313,  169],\n",
       "        [  19,   99,   24,  144,  308,  226,  223,  112,   14,   47],\n",
       "        [ 219,  243,  293,  303,  267,    8,   71,  294,  314,  229],\n",
       "        [ 317,  270,   39,  312,  105,  282,  305,   86,  284,  217],\n",
       "        [  68,  290,  150,  192,  272,  222,  273,   30,  258,  203],\n",
       "        [ 182,  235,  137,  113,  278,  186,  281,   40,  121,  299],\n",
       "        [  52,   96,  122,  165,  297,  246,   49,   12,  153,  175],\n",
       "        [ 206,  190,  170,  106,    6,  191,  279,  197,   92,    4],\n",
       "        [  81,  231,   23,  151,   50,  157,  210,  136,  208,    7],\n",
       "        [ 266,  125,   84,  176,  111,   48,  131,  301,  311,  289],\n",
       "        [ 204,   17,  315,   31,   18,  227,  236,   10,  103,  164],\n",
       "        [  98,  163,  156,  195,  225,  260,  220,   75,  127,  245],\n",
       "        [ 241,    2,   26,  120,  159,   66,  216,  302,  162,   43],\n",
       "        [ 287,  288,  129,    1,   90,  142,   79,  147,  143,  116],\n",
       "        [ 123,  141,  161,  261,   21,  183,   87,  214,  140,  304],\n",
       "        [  61,  200,  110,  228,  240,  184,  126,   69,  230,  285],\n",
       "        [  16,  101,  251,   38,  307,  185,  207,   41,   27,   70],\n",
       "        [   9,   62,  117,  132,   58,   72,   95,  173,  187,   94],\n",
       "        [ 263,  196,  283,  134,  171,   82,  172,   53,   51,    5],\n",
       "        [ 280,  256,  218,  108,  193,   36,   22,  199,  249,  275],\n",
       "        [ 167,   15,   78,  257,  100,  177,  201,   93,   74,  247],\n",
       "        [ 189,  168,  160,   67,  178,  237,  166,   45,  221,  259],\n",
       "        [ 253,   35,  174,  213,  145,   13,   46,   44,  198,   65],\n",
       "        [ 295,  268,   73,  265,  194,  291,   55,  119,  274,  139],\n",
       "        [  80,  107,  276,  255,   32,  205,   34,  104,   28,  254],\n",
       "        [ 306,  224,   89,  239,   83,  277,   54,  128,  154,  181],\n",
       "        [ 250,  242,  319,  138,  286,   37,   88,  238,  264,  269],\n",
       "        [ 102,   91,  202,  292,  118,  233,  188,   33,  158,   60],\n",
       "        [ 155,  135,  149,   97,  130,  298,  234,   63,  262,  300],\n",
       "        [ 209,  109,  212,  148,   76,   64,  152,  211,  124,  310]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input # 길이 10개짜리 문장의 32개 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rnn(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TODO : Sentence Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data/train.txt를 torchtext로 load하시오(배치사이즈 5)\n",
    "* Bidirectional LSTM을 선언(num_layers=2)\n",
    "* 마지막 히든 스테이트를 이용하여 Binary Classifier를 만드시오(Many-to-One)\n",
    "* train 시키시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field,Iterator,TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=tagger.morphs,use_vocab=True, batch_first=True)\n",
    "LABEL = Field(sequential=False,use_vocab=True,unk_token=None)\n",
    "\n",
    "train_data = TabularDataset(path=\"data/train.txt\",\n",
    "                            format=\"tsv\",\n",
    "                            fields=[('TEXT',TEXT),('LABEL',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', '\"', '배고프', '다', '밥', '주', '어', '\"', ',', '\"', 'FOOD', '\"', ']', ',']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'LABEL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0c23a313750a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'LABEL'"
     ]
    }
   ],
   "source": [
    "print(train_data.examples[0].TEXT)\n",
    "print(train_data.examples[0].LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  Iterator(train_data, batch_size=5, device=-1, # device -1 : cpu, device 0 : 남는 gpu\n",
    "    sort_key=lambda x: len(x.TEXT),sort_within_batch=True,repeat=False) # x.TEXT 길이 기준으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,embed_size,hidden_size,output_size,num_layers=1,bidirec=False):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirec:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "            \n",
    "        self.embed = nn.Embedding(input_size,embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,num_layers,batch_first=True,bidirectional=bidirec)\n",
    "        self.linear = nn.Linear(hidden_size*self.num_directions,output_size)\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        hidden = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        cell = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        return hidden, cell\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs : B,T\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs) # word vector indexing\n",
    "        hidden, cell = self.init_hidden(inputs.size(0)) # initial hidden,cell\n",
    "        \n",
    "        output, (hidden,cell) = self.lstm(embed,(hidden,cell))\n",
    "        \n",
    "        # Many-to-One\n",
    "        hidden = hidden[-self.num_directions:] # (num_directions,B,H)\n",
    "        hidden = torch.cat([h for h in hidden],1)\n",
    "        output = self.linear(hidden) # last hidden\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(len(TEXT.vocab),30,50,len(LABEL.vocab),bidirec=True)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    model.zero_grad()\n",
    "    preds = model(batch.TEXT)\n",
    "    loss = loss_function(preds,batch.LABEL)\n",
    "    print(loss.data[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
