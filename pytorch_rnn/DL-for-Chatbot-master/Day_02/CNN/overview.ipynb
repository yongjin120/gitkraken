{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:26:17.384566Z",
     "start_time": "2017-09-16T03:26:17.363600Z"
    }
   },
   "outputs": [],
   "source": [
    "from configs import get_config\n",
    "from data_loader import get_loader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:05:09.231919Z",
     "start_time": "2017-09-15T23:05:09.214349Z"
    }
   },
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:27:01.547111Z",
     "start_time": "2017-09-16T03:27:01.509562Z"
    }
   },
   "outputs": [],
   "source": [
    "config = get_config(\n",
    "    parse=False,\n",
    "    vocab_size=20000,\n",
    "    hidden_size=100,\n",
    "    n_channel_per_window=2,\n",
    "    label_size=2,\n",
    "    dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:27:02.607693Z",
     "start_time": "2017-09-16T03:27:02.582059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configurations\n",
       "{'batch_size': 100,\n",
       " 'data_dir': PosixPath('/Users/jmin/workspace/fastcampus_chatbot/Day_02/CNN/datasets'),\n",
       " 'dropout': 0.5,\n",
       " 'epochs': 20,\n",
       " 'hidden_size': 100,\n",
       " 'label_size': 2,\n",
       " 'log_every_epoch': 1,\n",
       " 'loss_fn': <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
       " 'lr': 0.001,\n",
       " 'n_channel_per_window': 2,\n",
       " 'optimizer': <class 'torch.optim.sgd.SGD'>,\n",
       " 'save_dir': PosixPath('/Users/jmin/workspace/fastcampus_chatbot/Day_02/CNN/log'),\n",
       " 'save_every_epoch': 1,\n",
       " 'vocab_size': 20000}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:28:51.163991Z",
     "start_time": "2017-09-16T03:28:36.077103Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocabulary \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_loader(batch_size=20, max_size=config.vocab_size, is_train=True, data_dir='./datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:29:56.105251Z",
     "start_time": "2017-09-16T03:29:55.791747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.batch.Batch at 0x1284279b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:30:15.468968Z",
     "start_time": "2017-09-16T03:30:15.448890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  3249    127   2623  ...     524    213   3657\n",
       "    20     12    159  ...      12     13      9\n",
       "     6     27    152  ...     376    785    173\n",
       "        ...            ⋱           ...         \n",
       "     1      1      1  ...       1      1      1\n",
       "     1      1      1  ...       1      1      1\n",
       "     1      1      1  ...       1      1      1\n",
       "[torch.LongTensor of size 71x20]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [max_seq_len, batch_size]\n",
    "batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:26:26.059147Z",
     "start_time": "2017-09-15T23:26:26.040908Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.LongTensor of size 20]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch_size]\n",
    "batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cnn_text_classification.png\", width=600, height=60>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:23:17.286946Z",
     "start_time": "2017-09-15T23:23:17.138573Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNN, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        \n",
    "        self.conv = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(3, config.hidden_size)),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(4, config.hidden_size)),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=config.n_channel_per_window,\n",
    "                kernel_size=(5, config.hidden_size))\n",
    "        ])\n",
    "        \n",
    "        n_total_channels = len(self.conv) * config.n_channel_per_window\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(n_total_channels, config.label_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, max_seq_len]\n",
    "        Return:\n",
    "            logit: [batch_size, label_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        # [batch_size, max_seq_len, hidden_size]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # [batch_size, 1, max_seq_len, hidden_size]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Apply Convolution filter followed by Max-pool\n",
    "        out_list = []\n",
    "        for conv in self.conv:\n",
    "            \n",
    "            ########## Convolution #########\n",
    "            \n",
    "            # [batch_size, n_kernels, _, 1]\n",
    "            x_ = F.relu(conv(x))\n",
    "            \n",
    "            # [batch_size, n_kernels, _]\n",
    "            x_ = x_.squeeze(3)\n",
    "            \n",
    "            ########## Max-pool #########\n",
    "            \n",
    "            # [batch_size, n_kernels, 1]\n",
    "            x_ = F.max_pool1d(x_, x_.size(2))\n",
    "            \n",
    "            # [batch_size, n_kernels]\n",
    "            x_ = x_.squeeze(2)\n",
    "            \n",
    "            out_list.append(x_)\n",
    "        \n",
    "        # [batch_size, 3 x n_kernels]\n",
    "        out = torch.cat(out_list, 1)\n",
    "        \n",
    "        ######## Dropout ########\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # [batch_size, label_size]\n",
    "        logit = self.fc(out)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:37:22.244599Z",
     "start_time": "2017-09-16T03:37:22.141461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:37:23.279811Z",
     "start_time": "2017-09-16T03:37:23.256595Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN (\n",
       "  (embedding): Embedding(20000, 100)\n",
       "  (conv): ModuleList (\n",
       "    (0): Conv2d(1, 2, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 2, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 2, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout (p = 0.5)\n",
       "  (fc): Linear (6 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:37:54.333787Z",
     "start_time": "2017-09-16T03:37:54.305905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss (\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = config.loss_fn()\n",
    "\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T23:33:07.947242Z",
     "start_time": "2017-09-15T23:33:07.930075Z"
    }
   },
   "source": [
    "# Build Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:37:57.383866Z",
     "start_time": "2017-09-16T03:37:57.363663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.sgd.SGD at 0x13cb046d8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = config.optimizer(model.parameters(), config.lr)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-16T03:40:13.335050Z",
     "start_time": "2017-09-16T03:39:48.315397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/7302 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1/7302 [00:00<42:00,  2.90it/s]\u001b[A\n",
      "  0%|          | 4/7302 [00:00<31:01,  3.92it/s]\u001b[A\n",
      "  0%|          | 7/7302 [00:00<23:15,  5.23it/s]\u001b[A\n",
      "  0%|          | 10/7302 [00:00<17:45,  6.84it/s]\u001b[A\n",
      "  0%|          | 13/7302 [00:00<13:39,  8.89it/s]\u001b[A\n",
      "  0%|          | 17/7302 [00:00<10:40, 11.37it/s]\u001b[A\n",
      "  0%|          | 20/7302 [00:01<08:41, 13.96it/s]\u001b[A\n",
      "  0%|          | 24/7302 [00:01<07:20, 16.53it/s]\u001b[A\n",
      "  0%|          | 27/7302 [00:01<06:42, 18.09it/s]\u001b[A\n",
      "  0%|          | 30/7302 [00:01<06:20, 19.11it/s]\u001b[A\n",
      "  0%|          | 33/7302 [00:01<05:50, 20.72it/s]\u001b[A\n",
      "  1%|          | 37/7302 [00:01<05:22, 22.53it/s]\u001b[A\n",
      "  1%|          | 40/7302 [00:01<05:40, 21.31it/s]\u001b[A\n",
      "  1%|          | 43/7302 [00:01<05:17, 22.84it/s]\u001b[A\n",
      "  1%|          | 46/7302 [00:02<04:55, 24.52it/s]\u001b[A\n",
      "  1%|          | 49/7302 [00:02<04:43, 25.57it/s]\u001b[A\n",
      "          \n",
      " 11%|█▏        | 839/7302 [4:02:08<31:05:18, 17.32s/it]\n",
      "  1%|          | 52/7302 [00:02<05:09, 23.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6101\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 55/7302 [00:02<05:22, 22.49it/s]\u001b[A\n",
      "  1%|          | 58/7302 [00:02<05:12, 23.21it/s]\u001b[A\n",
      "  1%|          | 61/7302 [00:02<05:24, 22.30it/s]\u001b[A\n",
      "  1%|          | 64/7302 [00:02<05:22, 22.47it/s]\u001b[A\n",
      "  1%|          | 67/7302 [00:02<05:06, 23.64it/s]\u001b[A\n",
      "  1%|          | 70/7302 [00:03<05:01, 23.99it/s]\u001b[A\n",
      "  1%|          | 73/7302 [00:03<05:10, 23.31it/s]\u001b[A\n",
      "  1%|          | 76/7302 [00:03<05:11, 23.18it/s]\u001b[A\n",
      "  1%|          | 79/7302 [00:03<05:01, 23.97it/s]\u001b[A\n",
      "  1%|          | 82/7302 [00:03<05:26, 22.09it/s]\u001b[A\n",
      "  1%|          | 85/7302 [00:03<05:08, 23.36it/s]\u001b[A\n",
      "  1%|          | 88/7302 [00:03<04:57, 24.28it/s]\u001b[A\n",
      "  1%|▏         | 92/7302 [00:04<04:40, 25.71it/s]\u001b[A\n",
      "  1%|▏         | 95/7302 [00:04<04:37, 25.97it/s]\u001b[A\n",
      "  1%|▏         | 98/7302 [00:04<04:32, 26.45it/s]\u001b[A\n",
      "          \n",
      " 11%|█▏        | 839/7302 [4:02:10<31:05:34, 17.32s/it]\n",
      "  1%|▏         | 101/7302 [00:04<04:53, 24.55it/s]\u001b[A\n",
      "  1%|▏         | 104/7302 [00:04<04:58, 24.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 107/7302 [00:04<04:54, 24.42it/s]\u001b[A\n",
      "  2%|▏         | 110/7302 [00:04<04:40, 25.65it/s]\u001b[A\n",
      "  2%|▏         | 113/7302 [00:04<04:55, 24.35it/s]\u001b[A\n",
      "  2%|▏         | 116/7302 [00:05<05:17, 22.63it/s]\u001b[A\n",
      "  2%|▏         | 120/7302 [00:05<04:53, 24.46it/s]\u001b[A\n",
      "  2%|▏         | 123/7302 [00:05<04:52, 24.51it/s]\u001b[A\n",
      "  2%|▏         | 126/7302 [00:05<04:42, 25.38it/s]\u001b[A\n",
      "  2%|▏         | 129/7302 [00:05<04:58, 24.03it/s]\u001b[A\n",
      "  2%|▏         | 132/7302 [00:05<05:01, 23.79it/s]\u001b[A\n",
      "  2%|▏         | 135/7302 [00:05<04:55, 24.25it/s]\u001b[A\n",
      "  2%|▏         | 139/7302 [00:05<04:36, 25.94it/s]\u001b[A\n",
      "  2%|▏         | 142/7302 [00:06<04:25, 26.94it/s]\u001b[A\n",
      "  2%|▏         | 145/7302 [00:06<04:42, 25.35it/s]\u001b[A\n",
      "  2%|▏         | 148/7302 [00:06<04:50, 24.61it/s]\u001b[A\n",
      "          \n",
      " 11%|█▏        | 839/7302 [4:02:12<31:05:50, 17.32s/it]\n",
      "  2%|▏         | 151/7302 [00:06<04:55, 24.21it/s]\u001b[A\n",
      "  2%|▏         | 154/7302 [00:06<04:49, 24.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7033\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 157/7302 [00:06<05:11, 22.95it/s]\u001b[A\n",
      "  2%|▏         | 160/7302 [00:06<04:58, 23.95it/s]\u001b[A\n",
      "  2%|▏         | 163/7302 [00:06<04:44, 25.08it/s]\u001b[A\n",
      "  2%|▏         | 166/7302 [00:07<04:41, 25.36it/s]\u001b[A\n",
      "  2%|▏         | 169/7302 [00:07<04:37, 25.75it/s]\u001b[A\n",
      "  2%|▏         | 172/7302 [00:07<04:39, 25.49it/s]\u001b[A\n",
      "  2%|▏         | 175/7302 [00:07<04:54, 24.16it/s]\u001b[A\n",
      "  2%|▏         | 178/7302 [00:07<05:04, 23.38it/s]\u001b[A\n",
      "  2%|▏         | 181/7302 [00:07<05:03, 23.46it/s]\u001b[A\n",
      "  3%|▎         | 184/7302 [00:07<04:44, 25.06it/s]\u001b[A\n",
      "  3%|▎         | 187/7302 [00:07<04:33, 25.97it/s]\u001b[A\n",
      "  3%|▎         | 190/7302 [00:07<04:23, 26.99it/s]\u001b[A\n",
      "  3%|▎         | 193/7302 [00:08<04:16, 27.76it/s]\u001b[A\n",
      "  3%|▎         | 196/7302 [00:08<04:30, 26.25it/s]\u001b[A\n",
      "  3%|▎         | 199/7302 [00:08<05:01, 23.55it/s]\u001b[A\n",
      "          \n",
      " 11%|█▏        | 839/7302 [4:02:14<31:06:05, 17.32s/it]\n",
      "  3%|▎         | 202/7302 [00:08<04:54, 24.09it/s]\u001b[A\n",
      "  3%|▎         | 205/7302 [00:08<04:38, 25.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7690\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 208/7302 [00:08<04:59, 23.71it/s]\u001b[A\n",
      "  3%|▎         | 211/7302 [00:08<05:08, 23.00it/s]\u001b[A\n",
      "  3%|▎         | 254/7302 [00:10<04:15, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.8075\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 305/7302 [00:12<04:33, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7300\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 354/7302 [00:14<04:23, 26.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.6384\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 404/7302 [00:16<04:23, 26.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.9197\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 452/7302 [00:17<04:40, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7895\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 503/7302 [00:19<04:03, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7296\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 553/7302 [00:21<03:47, 29.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.7809\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 604/7302 [00:23<04:27, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: \n",
      " 0.8771\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 640/7302 [00:24<03:53, 28.48it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a30c1ac84de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# [batch_size, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-9ce04d6a079a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# [batch_size, 3 x n_kernels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m######## Dropout ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mldemo/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0m_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "  9%|▉         | 640/7302 [00:38<06:44, 16.46it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # n_epochs\n",
    "    print(f'Epoch: {epoch}')\n",
    "    for batch_i, batch in enumerate(tqdm(train_loader)):\n",
    "        # text: [max_seq_len, batch_size]\n",
    "        # label: [batch_size]\n",
    "        text, label = batch.text, batch.label\n",
    "\n",
    "        # [batch_size, max_seq_len]\n",
    "        text.data.t_()\n",
    "        \n",
    "        # [batch_size, 2]\n",
    "        logit = model(text)\n",
    "        \n",
    "        # Calculate loss\n",
    "        batch_loss = loss_fn(logit, label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_i + 1) % 50 == 0:\n",
    "            tqdm.write(f'batch loss: {batch_loss.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mldemo]",
   "language": "python",
   "name": "conda-env-mldemo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
