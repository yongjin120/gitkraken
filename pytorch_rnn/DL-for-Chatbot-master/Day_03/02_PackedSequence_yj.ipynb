{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed RNN inputs with variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence, pad_packed_sequence\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-padded input\n",
    "x = Variable(torch.Tensor([\n",
    "    [[1., 1.], [1., 1.], [1., 1.], [1., 1.], [1., 1.]],\n",
    "    [[2., 2.], [2., 2.], [2., 2.], [0., 0.], [0., 0.]],\n",
    "    [[3., 3.], [0., 0.], [0., 0.], [0., 0.], [0., 0.]]]))\n",
    "\n",
    "# list of valid length of each batch\n",
    "batch_sizes = [5, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(1 ,.,.) = \n",
      "  2  2\n",
      "  2  2\n",
      "  2  2\n",
      "  0  0\n",
      "  0  0\n",
      "\n",
      "(2 ,.,.) = \n",
      "  3  3\n",
      "  0  0\n",
      "  0  0\n",
      "  0  0\n",
      "  0  0\n",
      "[torch.FloatTensor of size 3x5x2]\n",
      " \n",
      "[batch_size, max_seq_len, input_size]\n"
     ]
    }
   ],
   "source": [
    "x\n",
    "print(x,'\\n[batch_size, max_seq_len, input_size]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pack_padded_sequence\n",
    "### torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False)\n",
    "### Save values dynamically from zero-padded inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packs a Tensor containing padded sequences of variable length.<br/>\n",
    "\n",
    "Input can be of size `T x B x *` where T is the length of the longest sequence (equal to lengths[0]), B is the batch size, and `*` is any number of dimensions (including 0). If `batch_first` is True `B x T x *` inputs are expected.\n",
    "\n",
    "The sequences should be sorted by length in a decreasing order, i.e. `input[:,0]` should be the longest sequence, and `input[:,B-1]` the shortest one.\n",
    "\n",
    "This function accepts any input that has at least two dimensions. You can apply it to pack the labels, and use the output of the RNN with them to compute the loss directly. A Tensor can be retrieved from a PackedSequence object by accessing its `.data `attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Parameters:\t\n",
    "  - input (Tensor) – padded batch of variable length sequences.\n",
    "  - lengths (Tensor) – list of sequences lengths of each batch element.\n",
    "  - batch_first (bool, optional) – if True, the input is expected in B x T x * format.\n",
    "  \n",
    "> Returns:\t\n",
    "  - a PackedSequence object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "    1     1\n",
       "    2     2\n",
       "    3     3\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    1     1\n",
       "[torch.FloatTensor of size 9x2]\n",
       ", batch_sizes=[3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_x = pack_padded_sequence(\n",
    "    input=x,\n",
    "    lengths=[5, 3, 1], # list of length of each batch\n",
    "    batch_first=True # input shape: [batch_first, max_seq_len, input_size]\n",
    ")\n",
    "packed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  1  1\n",
       "  2  2\n",
       "  3  3\n",
       "\n",
       "(1 ,.,.) = \n",
       "  1  1\n",
       "  2  2\n",
       "  0  0\n",
       "\n",
       "(2 ,.,.) = \n",
       "  1  1\n",
       "  2  2\n",
       "  0  0\n",
       "\n",
       "(3 ,.,.) = \n",
       "  1  1\n",
       "  0  0\n",
       "  0  0\n",
       "\n",
       "(4 ,.,.) = \n",
       "  1  1\n",
       "  0  0\n",
       "  0  0\n",
       "[torch.FloatTensor of size 5x3x2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_T = x.transpose(0, 1)\n",
    "x_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "    1     1\n",
       "    2     2\n",
       "    3     3\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    1     1\n",
       "[torch.FloatTensor of size 9x2]\n",
       ", batch_sizes=[3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_x_T = pack_padded_sequence(\n",
    "    input=x_T,\n",
    "    lengths=[5, 3, 1], # list of length of each batch\n",
    "    batch_first=False # [max_seq_len, batch_first, input_size]\n",
    ")\n",
    "packed_x_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PackedSequence\n",
    "#### torch.nn.utils.rnn.PackedSequence(cls, *args)\n",
    "* internal\n",
    "\n",
    "```\n",
    "PackedSequence_ = namedtuple('PackedSequence', ['data', 'batch_sizes'])\n",
    "class PackedSequence(PackedSequence_):\n",
    "    pass\n",
    "```\n",
    "* Args:\n",
    "    * data (Variable) <= **zero-padded** tensor\n",
    "    * batch_sizes (list of int) <= **in decreasing order**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holds the data and list of `batch_sizes` of a packed sequence.\n",
    "\n",
    "All RNN modules accept packed sequences as inputs.\n",
    "\n",
    "### Note\n",
    "\n",
    "Instances of this class should never be created manually. They are meant to be instantiated by functions like `pack_padded_sequence()`.\n",
    "\n",
    "Batch sizes represent the number elements at each sequence step in the batch, not the varying sequence lengths passed to `pack_padded_sequence()`. For instance, given data abc and x the `PackedSequenc`e would contain data `axbc` with `batch_sizes=[2,1,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  2\n",
       "  2  2\n",
       "  2  2\n",
       "  0  0\n",
       "  0  0\n",
       "\n",
       "(2 ,.,.) = \n",
       "  3  3\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "[torch.FloatTensor of size 3x5x2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "(0 ,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "  1  1\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  2\n",
       "  2  2\n",
       "  2  2\n",
       "  0  0\n",
       "  0  0\n",
       "\n",
       "(2 ,.,.) = \n",
       "  3  3\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "  0  0\n",
       "[torch.FloatTensor of size 3x5x2]\n",
       ", batch_sizes=[5, 3, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PackedSequence(x, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN takes PackedSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a linear transformation to the incoming `data: y=Ax+b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_backend': <torch.nn.backends.thnn.THNNFunctionBackend object at 0x0000000007630828>, '_parameters': OrderedDict([('weight', Parameter containing:\n",
      "-0.4197  0.1056\n",
      "[torch.FloatTensor of size 1x2]\n",
      "), ('bias', Parameter containing:\n",
      "-0.6356\n",
      "[torch.FloatTensor of size 1]\n",
      ")]), '_buffers': OrderedDict(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_modules': OrderedDict(), 'training': True, 'in_features': 2, 'out_features': 1}\n",
      "Variable containing:\n",
      "-0.1316 -0.1698\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.5983\n",
       "[torch.FloatTensor of size 1x1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(2, 1)\n",
    "print(vars(m))\n",
    "input = Variable(torch.randn(1, 2))\n",
    "print(input)\n",
    "output = (m(input))\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2, 2)\n",
    "rnn = nn.RNN(2, 2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "    1     1\n",
       "    2     2\n",
       "    3     3\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    2     2\n",
       "    1     1\n",
       "    1     1\n",
       "[torch.FloatTensor of size 9x2]\n",
       ", batch_sizes=[3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 4.1119  2.0264\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 1.8025  0.6315\n",
       " 1.8025  0.6315\n",
       "[torch.FloatTensor of size 9x2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(packed_x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 4.1119  2.0264\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 1.8025  0.6315\n",
       " 2.9572  1.3289\n",
       " 1.8025  0.6315\n",
       " 1.8025  0.6315\n",
       "[torch.FloatTensor of size 9x2]\n",
       ", batch_sizes=[3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_h = PackedSequence(linear(packed_x.data), packed_x.batch_sizes)\n",
    "packed_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed_y\n",
      " PackedSequence(data=Variable containing:\n",
      " 0.8189 -0.8096\n",
      " 0.9589 -0.8931\n",
      " 0.9912 -0.9411\n",
      " 0.8608 -0.6986\n",
      " 0.9712 -0.8224\n",
      " 0.8719 -0.7371\n",
      " 0.9724 -0.8369\n",
      " 0.8707 -0.7277\n",
      " 0.8712 -0.7302\n",
      "[torch.FloatTensor of size 9x2]\n",
      ", batch_sizes=[3, 2, 2, 1, 1]) \n",
      "\n",
      "last_h\n",
      " Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.8712 -0.7302\n",
      "  0.9724 -0.8369\n",
      "  0.9912 -0.9411\n",
      "[torch.FloatTensor of size 1x3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "packed_y, last_h = rnn(packed_h)\n",
    "print('packed_y\\n', packed_y,'\\n')\n",
    "print('last_h\\n', last_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_packed_sequence\n",
    "#### - zero-pad inputs and make it Tensor again\n",
    "\n",
    "* Args:\n",
    "    * sequence (PackedSequence)\n",
    "    * batch_first (bool)\n",
    "\n",
    "\n",
    "* Return:\n",
    "    * output (tuple of Variable)\n",
    "    * lengths (list of int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 0.8189 -0.8096\n",
       " 0.9589 -0.8931\n",
       " 0.9912 -0.9411\n",
       " 0.8608 -0.6986\n",
       " 0.9712 -0.8224\n",
       " 0.8719 -0.7371\n",
       " 0.9724 -0.8369\n",
       " 0.8707 -0.7277\n",
       " 0.8712 -0.7302\n",
       "[torch.FloatTensor of size 9x2]\n",
       ", batch_sizes=[3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.8189 -0.8096\n",
       "   0.8608 -0.6986\n",
       "   0.8719 -0.7371\n",
       "   0.8707 -0.7277\n",
       "   0.8712 -0.7302\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.9589 -0.8931\n",
       "   0.9712 -0.8224\n",
       "   0.9724 -0.8369\n",
       "   0.0000  0.0000\n",
       "   0.0000  0.0000\n",
       " \n",
       " (2 ,.,.) = \n",
       "   0.9912 -0.9411\n",
       "   0.0000  0.0000\n",
       "   0.0000  0.0000\n",
       "   0.0000  0.0000\n",
       "   0.0000  0.0000\n",
       " [torch.FloatTensor of size 3x5x2], [5, 3, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(packed_y, batch_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
